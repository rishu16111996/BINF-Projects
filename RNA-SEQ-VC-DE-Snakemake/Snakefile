
### Snakefile

```python
# DM1 RNA-Seq Variant Calling & Differential Expression Pipeline (Snakemake)
# Author: Rishabh Narula

import glob, os

# Load config
configfile: "config.yaml"

# Detect sample names from FASTQ files in the specified directory
FASTQ_DIR = config["datadirs"]["fastq"]
SAMPLES, = glob_wildcards(os.path.join(FASTQ_DIR, "{sample}_1.fastq.gz"))
READS = ["1", "2"]

# Define the final outputs for the workflow (joint VCF and MultiQC report)
rule all:
    input:
        # Final joint VCF and index
        os.path.join(config["datadirs"]["vcf"], "final_variants.vcf.gz"),
        os.path.join(config["datadirs"]["vcf"], "final_variants.vcf.gz.tbi"),
        # MultiQC report
        os.path.join(config["datadirs"]["qc"], "multiqc_report.html"),
        # Gene count files for each sample (for differential expression analysis)
        expand(os.path.join(config["datadirs"]["pass2"], "{sample}_ReadsPerGene.out.tab"), sample=SAMPLES)

# 1. Quality control with FastQC
rule fastqc:
    input:
        fq = os.path.join(FASTQ_DIR, "{sample}_{read}.fastq.gz")
    output:
        html = os.path.join(config["datadirs"]["qc"], "{sample}_{read}_fastqc.html"),
        zip  = os.path.join(config["datadirs"]["qc"], "{sample}_{read}_fastqc.zip")
    threads: 2
    shell:
        "fastqc --threads {threads} --outdir {config[datadirs][qc]} --nogroup {input.fq}"

# 2. Adapter trimming with Trim Galore (paired-end)
rule trim_galore:
    input:
        r1 = os.path.join(FASTQ_DIR, "{sample}_1.fastq.gz"),
        r2 = os.path.join(FASTQ_DIR, "{sample}_2.fastq.gz")
    output:
        r1_trimmed = os.path.join(config["datadirs"]["trim"], "{sample}_1_val_1.fq.gz"),
        r2_trimmed = os.path.join(config["datadirs"]["trim"], "{sample}_2_val_2.fq.gz")
    params:
        extra = "--illumina -q 20 --phred33 --length 20"
    threads: 4
    shell:
        "trim_galore {params.extra} --paired --cores {threads} "
        "--output_dir {config[datadirs][trim]} {input.r1} {input.r2}"

# 3. STAR first-pass alignment to discover splice junctions
rule star_first_pass:
    input:
        r1 = os.path.join(config["datadirs"]["trim"], "{sample}_1_val_1.fq.gz"),
        r2 = os.path.join(config["datadirs"]["trim"], "{sample}_2_val_2.fq.gz")
    output:
        sj = os.path.join(config["datadirs"]["bam"], "{sample}_SJ.out.tab")
    params:
        prefix = os.path.join(config["datadirs"]["bam"], "{sample}_")
    threads: 8
    shell:
        "STAR --runThreadN {threads} "
        "--genomeDir {config[reference][star_index]} "
        "--readFilesIn {input.r1} {input.r2} --readFilesCommand zcat "
        "--outFileNamePrefix {params.prefix} "
        "--outSAMtype None --outSJfilterReads All "
        "--outFilterType BySJout --outFilterMultimapNmax 20 "
        "--outFilterMismatchNmax 999 --outFilterMismatchNoverReadLmax 0.04 "
        "--alignIntronMin 20 --alignIntronMax 1000000 "
        "--alignSJoverhangMin 8 --alignSJDBoverhangMin 1 --sjdbScore 1"

# 4. Merge splice junctions from all samples (for second pass index)
rule merge_junctions:
    input:
        sjs = expand(os.path.join(config["datadirs"]["bam"], "{sample}_SJ.out.tab"), sample=SAMPLES)
    output:
        merged = os.path.join(config["datadirs"]["sj_files"], "SJ.out.pass1_merged.tab")
    shell:
        # Keep junctions supported by >=3 reads, merge unique entries
        "cat {input.sjs} | awk '$7 >= 3' | cut -f1-4 | sort -u > {output.merged}"

# 5. Generate STAR index incorporating novel junctions (second pass index)
rule star_index_pass2:
    input:
        fasta = config["reference"]["fasta"],
        gtf   = config["reference"]["gtf"],
        sjs   = os.path.join(config["datadirs"]["sj_files"], "SJ.out.pass1_merged.tab")
    output:
        idx_done = os.path.join(config["datadirs"]["stargenomedir"], "SAindex")
    params:
        outdir = config["datadirs"]["stargenomedir"]
    threads: 8
    shell:
        "STAR --runThreadN {threads} --runMode genomeGenerate "
        "--genomeDir {params.outdir} "
        "--genomeFastaFiles {input.fasta} "
        "--sjdbFileChrStartEnd {input.sjs} "
        "--sjdbGTFfile {input.gtf} --sjdbOverhang 149"

# 6. STAR second-pass alignment using updated index (with novel junctions)
rule star_second_pass:
    input:
        r1 = os.path.join(config["datadirs"]["trim"], "{sample}_1_val_1.fq.gz"),
        r2 = os.path.join(config["datadirs"]["trim"], "{sample}_2_val_2.fq.gz"),
        idx = os.path.join(config["datadirs"]["stargenomedir"], "SAindex")  # wait for index build
    output:
        # Coordinate-sorted BAM, transcriptome BAM, and gene counts
        bam_coord  = os.path.join(config["datadirs"]["pass2"], "{sample}_Aligned.sortedByCoord.out.bam"),
        bam_trans  = os.path.join(config["datadirs"]["pass2"], "{sample}_Aligned.toTranscriptome.out.bam"),
        gene_count = os.path.join(config["datadirs"]["pass2"], "{sample}_ReadsPerGene.out.tab")
    params:
        prefix = os.path.join(config["datadirs"]["pass2"], "{sample}_")
    threads: 8
    shell:
        "STAR --runThreadN {threads} "
        "--genomeDir {config[datadirs][stargenomedir]} "
        "--readFilesIn {input.r1} {input.r2} --readFilesCommand zcat "
        "--outFileNamePrefix {params.prefix} "
        "--outSAMtype BAM SortedByCoordinate "
        "--outSAMunmapped Within "
        "--quantMode TranscriptomeSAM GeneCounts "
        "--outSAMattributes NH HI AS NM MD "
        "--outFilterType BySJout --outFilterMultimapNmax 20 "
        "--outFilterMismatchNmax 999 --outFilterMismatchNoverReadLmax 0.04 "
        "--alignIntronMin 20 --alignIntronMax 1000000 "
        "--alignSJoverhangMin 8 --alignSJDBoverhangMin 1 --sjdbScore 1 "

# 7. Add Read Groups to aligned BAM
rule add_read_groups:
    input:
        bam = os.path.join(config["datadirs"]["pass2"], "{sample}_Aligned.sortedByCoord.out.bam")
    output:
        bam = os.path.join(config["datadirs"]["RGbam"], "{sample}_rg.bam")
    shell:
        "picard AddOrReplaceReadGroups I={input.bam} O={output.bam} "
        "RGID={wildcards.sample} RGLB=lib1 RGPL=illumina RGPU=unit1 RGSM={wildcards.sample}"

# 8. Mark duplicates
rule mark_duplicates:
    input:
        bam = os.path.join(config["datadirs"]["RGbam"], "{sample}_rg.bam")
    output:
        bam    = os.path.join(config["datadirs"]["dedup"], "{sample}_dedup.bam"),
        metrics = os.path.join(config["datadirs"]["dedup"], "{sample}_dedup.metrics.txt")
    shell:
        "picard MarkDuplicates I={input.bam} O={output.bam} M={output.metrics} CREATE_INDEX=true "

# 9. Split'N'Trim (Split CIGAR for reads spanning introns)
rule split_ncigar:
    input:
        bam = os.path.join(config["datadirs"]["dedup"], "{sample}_dedup.bam")
    output:
        bam = os.path.join(config["datadirs"]["splitNcigar"], "{sample}_split.bam")
    shell:
        "gatk SplitNCigarReads -R {config[reference][fasta]} -I {input.bam} -O {output.bam}"

# 10. Base Quality Score Recalibration (first pass)
rule bqsr_pass1:
    input:
        bam = os.path.join(config["datadirs"]["splitNcigar"], "{sample}_split.bam")
    output:
        table = os.path.join(config["datadirs"]["Recal1"], "{sample}_recal.table")
    shell:
        "gatk BaseRecalibrator -R {config[reference][fasta]} -I {input.bam} "
        "--known-sites {config[reference][known_sites_snp]} "
        "--known-sites {config[reference][known_sites_indel]} "
        "--known-sites {config[reference][dbsnp]} "
        "-O {output.table}"

# 11. Apply BQSR (first pass)
rule apply_bqsr_pass1:
    input:
        bam   = os.path.join(config["datadirs"]["splitNcigar"], "{sample}_split.bam"),
        table = os.path.join(config["datadirs"]["Recal1"], "{sample}_recal.table")
    output:
        bam = os.path.join(config["datadirs"]["BQSR_1"], "{sample}_recal.pass1.bam")
    shell:
        "gatk ApplyBQSR -R {config[reference][fasta]} -I {input.bam} "
        "--bqsr-recal-file {input.table} -O {output.bam}"

# 12. Base Quality Score Recalibration (second pass, to analyze covariate improvements)
rule bqsr_pass2:
    input:
        bam = os.path.join(config["datadirs"]["BQSR_1"], "{sample}_recal.pass1.bam")
    output:
        table = os.path.join(config["datadirs"]["Recal2"], "{sample}_recal2.table")
    shell:
        "gatk BaseRecalibrator -R {config[reference][fasta]} -I {input.bam} "
        "--known-sites {config[reference][known_sites_snp]} "
        "--known-sites {config[reference][known_sites_indel]} "
        "--known-sites {config[reference][dbsnp]} "
        "-O {output.table}"

# 13. Apply BQSR (second pass)
rule apply_bqsr_pass2:
    input:
        bam   = os.path.join(config["datadirs"]["BQSR_1"], "{sample}_recal.pass1.bam"),
        table = os.path.join(config["datadirs"]["Recal2"], "{sample}_recal2.table")
    output:
        bam = os.path.join(config["datadirs"]["BQSR_2"], "{sample}_final.bam")
    shell:
        "gatk ApplyBQSR -R {config[reference][fasta]} -I {input.bam} "
        "--bqsr-recal-file {input.table} -O {output.bam}"

# 14. Variant Calling with HaplotypeCaller (per sample GVCF)
rule haplotype_caller:
    input:
        bam = os.path.join(config["datadirs"]["BQSR_2"], "{sample}_final.bam")
    output:
        vcf = os.path.join(config["datadirs"]["vcf"], "{sample}.g.vcf.gz")
    params:
        ref = config["reference"]["fasta"]
    threads: 4
    shell:
        "gatk HaplotypeCaller -R {params.ref} -I {input.bam} -ERC GVCF -O {output.vcf}"

# 15. Combine GVCFs for joint genotyping
rule combine_gvcfs:
    input:
        vcfs = expand(os.path.join(config["datadirs"]["vcf"], "{sample}.g.vcf.gz"), sample=SAMPLES)
    output:
        combined = os.path.join(config["datadirs"]["vcf"], "combined.g.vcf.gz")
    params:
        ref = config["reference"]["fasta"]
    shell:
        "gatk CombineGVCFs -R {params.ref} "
        + " ".join(f"-V {vcf}" for vcf in input.vcfs) + " "
        f"-O {output.combined}"

# 16. Joint Genotyping to produce final VCF
rule genotype_gvcfs:
    input:
        gvcf = os.path.join(config["datadirs"]["vcf"], "combined.g.vcf.gz")
    output:
        vcf = os.path.join(config["datadirs"]["vcf"], "final_variants.vcf.gz")
    params:
        ref = config["reference"]["fasta"]
    shell:
        "gatk GenotypeGVCFs -R {params.ref} -V {input.gvcf} -O {output.vcf}"

# 17. Index the final VCF (tabix index for .vcf.gz)
rule index_final_vcf:
    input:
        vcf = os.path.join(config["datadirs"]["vcf"], "final_variants.vcf.gz")
    output:
        idx = os.path.join(config["datadirs"]["vcf"], "final_variants.vcf.gz.tbi")
    shell:
        "bcftools index -t {input.vcf}"

# 18. Generate MultiQC report (after FastQC and MarkDuplicates steps are done)
rule multiqc:
    input:
        fastqc_reports = expand(os.path.join(config["datadirs"]["qc"], "{sample}_{read}_fastqc.zip"), sample=SAMPLES, read=READS),
        dup_metrics    = expand(os.path.join(config["datadirs"]["dedup"], "{sample}_dedup.metrics.txt"), sample=SAMPLES)
    output:
        report = os.path.join(config["datadirs"]["qc"], "multiqc_report.html")
    shell:
        "multiqc -o {config[datadirs][qc]} {config[datadirs][fastq]} {config[datadirs][trim]} "
        "{config[datadirs][bam]} {config[datadirs][pass2]} {config[datadirs][dedup]} {config[datadirs][qc]}"
